{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6e40b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MersenneTwister(15095)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CSV, DataFrames, Statistics, GLMNet, Random, Gurobi, JuMP, LinearAlgebra\n",
    "Random.seed!(15095)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced62b5f",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5d66fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(CSV.File(\"clean_data.csv\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1b60e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_vars = names(df)[[28,29,30,31,32,33,34,35,36,37,38,39,40,\n",
    "        41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,\n",
    "        66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,\n",
    "        91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107]];\n",
    "liwc_df = df[:,liwc_vars];\n",
    "df = select(df,Not(liwc_vars));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e543fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove low base rate variables (< .05)\n",
    "base_rates = mean.(eachcol(liwc_df));\n",
    "low_base_rates = []\n",
    "for (i,e) in enumerate(base_rates)\n",
    "    if abs(e) <= .5\n",
    "        append!(low_base_rates,i)\n",
    "    end\n",
    "end\n",
    "liwc_df = select(liwc_df,Not(low_base_rates));\n",
    "df = hcat(df,liwc_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7f195cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test split\n",
    "n = nrow(df);\n",
    "split_point = convert(Int,ceil(0.8*n));\n",
    "shuffled_ind = randperm(n);\n",
    "train_ind = shuffled_ind[1:split_point];\n",
    "test_ind = shuffled_ind[(1+split_point):end];\n",
    "Xtrain,ytrain,Xtest,ytest = df[train_ind,Not(:plebe_cqpa)],df[train_ind,:plebe_cqpa],df[test_ind,Not(:plebe_cqpa)],df[test_ind,:plebe_cqpa];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72e21c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_r2 (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_r2(X,y,beta,beta_zero)\n",
    "    SSres = sum( (y .- X*beta .- beta_zero).^2 )\n",
    "    SStot = sum( (y .- Statistics.mean(y)).^2 )\n",
    "    return 1-SSres/SStot\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7b3f819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_mse (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_mse(X,y,beta,beta_zero)\n",
    "    n,p = size(X)\n",
    "    return sum((y .- X*beta .- beta_zero).^2)/n\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa8af42",
   "metadata": {},
   "source": [
    "# Old Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e6a5f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_old = (ytrain .- mean(ytrain))./std(ytrain);\n",
    "ytest_old = (ytest .- mean(ytest))./std(ytest);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09dbb597",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_old = Matrix(Xtrain[:,[:average_WC,:verb,:informal,:compare,:faculty_app_scr]]);\n",
    "Xtest_old = Matrix(Xtest[:,[:average_WC,:verb,:informal,:compare,:faculty_app_scr]]);\n",
    "\n",
    "Xtrain_old = (Xtrain_old .- mean(Xtrain_old,dims=1))./std(Xtrain_old,dims=1);\n",
    "Xtest_old = (Xtest_old .- mean(Xtest_old,dims=1))./std(Xtest_old,dims=1);\n",
    "\n",
    "Xtrain_old = coalesce(Xtrain_old,0);\n",
    "Xtest_old = coalesce(Xtest_old,0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5994f728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature names - for interpretability purposes\n",
    "feature_names = [\"Average WC\",\"Verb\",\"Informal\",\"Compare\",\"FAS\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6227e75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter: 0.001144532333395605 \n",
      "\n",
      "Selected Average WC with value 0.185812596343394\n",
      "Selected Verb with value -0.20239721606158242\n",
      "Selected Informal with value -0.06795163321405868\n",
      "Selected Compare with value 0.08104164196587725\n",
      "Selected FAS with value 0.3025071524449968\n"
     ]
    }
   ],
   "source": [
    "# Final model\n",
    "lasso_cv = glmnetcv(Xtrain_old,ytrain_old)\n",
    "best = argmin(lasso_cv.meanloss)\n",
    "beta_lasso = lasso_cv.path.betas[:,best]\n",
    "beta_zero_lasso = lasso_cv.path.a0[best]\n",
    "indices_lasso = [i for i=1:length(beta_lasso) if beta_lasso[i] != 0]\n",
    "\n",
    "lasso_lambda = lambdamin(lasso_cv)\n",
    "println(\"Hyperparameter: $(lasso_lambda) \\n\")\n",
    "\n",
    "for i in indices_lasso\n",
    "    println(\"Selected $(feature_names[i]) with value $(beta_lasso[i])\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a88c798e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2 = 0.192664382735646\n",
      "Test r2 = 0.17785414053677728\n",
      "\n",
      "Train MSE = 0.8072133122170485\n",
      "Test MSE = 0.8216475892453662\n",
      "\n",
      "Sparsity: 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(\"Train r2 = $(compute_r2(Xtrain_old,ytrain_old,beta_lasso,beta_zero_lasso))\")\n",
    "println(\"Test r2 = $(compute_r2(Xtest_old,ytest_old,beta_lasso,beta_zero_lasso))\")\n",
    "println()\n",
    "println(\"Train MSE = $(compute_mse(Xtrain_old,ytrain_old,beta_lasso,beta_zero_lasso))\")\n",
    "println(\"Test MSE = $(compute_mse(Xtest_old,ytest_old,beta_lasso,beta_zero_lasso))\")\n",
    "println()\n",
    "println(\"Sparsity: $(length(indices_lasso))\")\n",
    "println()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bebc8e",
   "metadata": {},
   "source": [
    "# New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe37d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_new = (ytrain .- mean(ytrain))./std(ytrain);\n",
    "ytest_new = (ytest .- mean(ytest))./std(ytest);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57f00118",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = names(df)[[12,20,21,22,23,24,25,28,29,30,31,32,33,34,35,36,37,38,39,40,\n",
    "        41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,\n",
    "        66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81]];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9dace01",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_new = Matrix(Xtrain[:,vars]);\n",
    "Xtest_new = Matrix(Xtest[:,vars]);\n",
    "\n",
    "Xtrain_new = coalesce.(Xtrain_new,0);\n",
    "Xtest_new = coalesce.(Xtest_new,0);\n",
    "\n",
    "Xtrain_new = (Xtrain_new .- mean(Xtrain_new,dims=1))./std(Xtrain_new,dims=1);\n",
    "Xtest_new = (Xtest_new .- mean(Xtest_new,dims=1))./std(Xtest_new,dims=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4edf57b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature names - for interpretability purposes\n",
    "features = vars\n",
    "p = length(features)\n",
    "feature_names = []\n",
    "for i=1:p\n",
    "    append!(feature_names,[features[i]])\n",
    "    append!(feature_names,[features[i]*\"_squared\"])\n",
    "    append!(feature_names,[features[i]*\"_sqrt\"])\n",
    "    append!(feature_names,[features[i]*\"_log\"])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a9de6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_HC (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Holistic regression auxiliary functions\n",
    "\n",
    "function compute_nonlinear_transformations(X::Matrix{Float64})\n",
    "    n,p0 = size(X)\n",
    "    p = p0 + p0*3\n",
    "    X_ext = zeros(n,p)\n",
    "    \n",
    "    col_num = 1\n",
    "    for j0=1:p0\n",
    "        X_ext[:,col_num] .= X[:,j0]\n",
    "        col_num += 1\n",
    "        for j=1:3\n",
    "            if j == 1\n",
    "                X_ext[:,col_num] .= X[:,j0].^2\n",
    "            elseif j == 2\n",
    "                X_ext[:,col_num] .= abs.(X[:,j0]).^0.5\n",
    "            elseif j == 3\n",
    "                X_ext[:,col_num] .= log.(abs.(X[:,j0]).+1) \n",
    "            end\n",
    "            col_num += 1\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return X_ext\n",
    "end  \n",
    "\n",
    "function compute_HC(X::Matrix{Float64},ρ_max::Float64)\n",
    "    n,p = size(X)\n",
    "    c = zeros(p,p)\n",
    "    for i=1:p-1,j=i+1:p\n",
    "        c[i,j] = cor(X[:,i],X[:,j])\n",
    "    end\n",
    "    return [(i,j) for i=1:p for j=i+1:p if abs(c[i,j])>ρ_max]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a758e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "holistic (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function holistic(X::Matrix{Float64},Y::Vector{Float64},Γ::Float64,k::Int,ρ_max::Float64)\n",
    "\n",
    "    n,p0 = size(X)\n",
    "    M = 30\n",
    "    # NOTE: Select big-M by inspecting the absolute maginitude of the lasso coefficients\n",
    "    \n",
    "    X_extended = compute_nonlinear_transformations(X)\n",
    "    n,p = size(X_extended)\n",
    "        \n",
    "    HC = compute_HC(X_extended,ρ_max)\n",
    "    \n",
    "    m = Model(Gurobi.Optimizer)\n",
    "    set_optimizer_attribute(m,\"OutputFlag\",0)\n",
    "    set_time_limit_sec(m, 60.0)\n",
    "    \n",
    "    @variable(m, β0)\n",
    "    @variable(m, β[1:p])\n",
    "    @variable(m, w[1:p])\n",
    "    @variable(m, z[1:p], Bin)\n",
    "\n",
    "    # Linearize l1 norm\n",
    "    @constraint(m, [i=1:p], w[i] >= β[i])\n",
    "    @constraint(m, [i=1:p], w[i] >= -β[i])\n",
    "\n",
    "    # Big M and sparsity\n",
    "    @constraint(m, sum(z) <= k)\n",
    "    @constraint(m, [i=1:p], β[i] >= -M*z[i])\n",
    "    @constraint(m, [i=1:p], β[i] <= M*z[i])\n",
    "\n",
    "    # Pairwise correlation\n",
    "    for (i,j) in HC\n",
    "        @constraint(m, z[i] + z[j] <= 1)\n",
    "    end\n",
    "    \n",
    "    # Transformations\n",
    "    j = 1\n",
    "    for j0=1:p0\n",
    "        @constraint(m, sum(z[j+j_transf] for j_transf=0:3) <= 1)\n",
    "        j += 4\n",
    "    end\n",
    "\n",
    "    # Objective (w robustness)\n",
    "    res = 0.5*sum((Y[i]-dot(X_extended[i,:],β)-β0)^2 for i=1:n)\n",
    "    reg = sum(w[i] for i=1:p)\n",
    "    @objective(m,Min,res + Γ*reg)\n",
    "\n",
    "    optimize!(m)\n",
    "                    \n",
    "    return value.(β), value(β0)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa526cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "holistic_cv (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function holistic_cv(X::Matrix{Float64}, Y::Vector{Float64}, Γ_vals, k_vals, ρ_max_vals)\n",
    "\n",
    "    n,p = size(X)\n",
    "    \n",
    "    # Train and validation split\n",
    "    split_point = convert(Int, ceil(0.8*n))\n",
    "    shuffled_ind = randperm(n)\n",
    "    train_ind = shuffled_ind[1:split_point]\n",
    "    valid_ind = shuffled_ind[(1+split_point):end]\n",
    "    train_X, train_y, valid_X, valid_y = X[train_ind,:], Y[train_ind], X[valid_ind,:], Y[valid_ind]\n",
    "    valid_X_ex = compute_nonlinear_transformations(valid_X)\n",
    "\n",
    "    cv_path = DataFrame(k=Int[], Γ=Float64[], ρ_max=Float64[], valid_score=Float64[])\n",
    "    \n",
    "    for ρ_max in ρ_max_vals, Γ in Γ_vals, k in k_vals\n",
    "        β,β0 = holistic(train_X,train_y,Γ,k,ρ_max)\n",
    "        r2 = compute_r2(valid_X_ex,valid_y,β,β0)\n",
    "        push!(cv_path,[k,Γ,ρ_max,r2])\n",
    "    end\n",
    "\n",
    "    # Refit\n",
    "    best = argmax(cv_path.valid_score)\n",
    "    Γ,k,ρ_max = cv_path.Γ[best], cv_path.k[best], cv_path.ρ_max[best]\n",
    "    params = (Γ,k,ρ_max)\n",
    "    β,β0 = holistic(X,Y,Γ,k,ρ_max)\n",
    "    \n",
    "    return β,β0,Γ\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "924ca942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2022-09-12\r\n",
      "Academic license - for non-commercial use only - expires 2022-09-12\r\n",
      "Academic license - for non-commercial use only - expires 2022-09-12\r\n",
      "Academic license - for non-commercial use only - expires 2022-09-12\r\n",
      "Academic license - for non-commercial use only - expires 2022-09-12\r\n",
      "Academic license - for non-commercial use only - expires 2022-09-12\r\n",
      "Academic license - for non-commercial use only - expires 2022-09-12\r\n",
      "Academic license - for non-commercial use only - expires 2022-09-12\r\n",
      "Academic license - for non-commercial use only - expires 2022-09-12\r\n",
      "Academic license - for non-commercial use only - expires 2022-09-12\r\n",
      "\n",
      "Optimal lambda: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Regularization\n",
    "Γ_vals = [.001,.005,.01,.03,.1,.2,.3,.5,1.0]\n",
    "\n",
    "# Sparsity\n",
    "k_vals = [5]\n",
    "\n",
    "# Correlation\n",
    "ρ_max_vals = [0.7]\n",
    "\n",
    "β,β0,lambda = holistic_cv(Xtrain_new,ytrain_new,Γ_vals,k_vals,ρ_max_vals);\n",
    "indices_holistic = [i for i=1:length(β) if abs(β[i]) > .00001];\n",
    "println(\"\\nOptimal lambda: $lambda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c5d170c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected faculty_app_scr with value 0.3150534387471893\n",
      "Selected average_WC with value 0.2530560652291454\n",
      "Selected compare with value 0.11018430156657338\n",
      "Selected social with value -0.24064918513000652\n",
      "Selected insight_squared with value 0.06342273973248637\n"
     ]
    }
   ],
   "source": [
    "for i in indices_holistic\n",
    "    println(\"Selected $(feature_names[i]) with value $(β[i])\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c640c5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train r2 = 0.20207641727241854\n",
      "Test r2 = 0.18932714911810922\n",
      "\n",
      "Train MSE = 0.7978027035300771\n",
      "Test MSE = 0.8101815340025684\n",
      "\n",
      "Sparsity: 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Xtrain_new_ex = compute_nonlinear_transformations(Xtrain_new)\n",
    "Xtest_new_ex = compute_nonlinear_transformations(Xtest_new)\n",
    "\n",
    "println(\"Train r2 = $(compute_r2(Xtrain_new_ex,ytrain_new,β,β0))\")\n",
    "println(\"Test r2 = $(compute_r2(Xtest_new_ex,ytest_new,β,β0))\")\n",
    "println()\n",
    "println(\"Train MSE = $(compute_mse(Xtrain_new_ex,ytrain_new,β,β0))\")\n",
    "println(\"Test MSE = $(compute_mse(Xtest_new_ex,ytest_new,β,β0))\")\n",
    "println()\n",
    "println(\"Sparsity: $(length(indices_holistic))\")\n",
    "println()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b40329",
   "metadata": {},
   "source": [
    "# Mean Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03c47d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_mean = (ytrain .- mean(ytrain))./std(ytrain);\n",
    "ytest_mean = (ytest .- mean(ytest))./std(ytest);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4b4e55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_mean = deepcopy(Xtrain);\n",
    "Xtest_mean = deepcopy(Xtest);\n",
    "\n",
    "vars = names(df)[[12,20,21,22,23,24,25,28,29,30,31,32,33,34,35,36,37,38,39,40,\n",
    "        41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,\n",
    "        66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81]];\n",
    "\n",
    "Xtrain_mean = Xtrain_mean[:,vars];\n",
    "Xtest_mean = Xtest_mean[:,vars];\n",
    "\n",
    "Xtrain_mean = coalesce.(Xtrain_mean,0);\n",
    "Xtest_mean = coalesce.(Xtest_mean,0);\n",
    "\n",
    "Xtrain_mean[!,:faculty_app_scr] = convert.(Float64,Xtrain_mean[!,:faculty_app_scr]);\n",
    "Xtrain_mean[!,:min_WC] = convert.(Float64,Xtrain_mean[!,:min_WC]);\n",
    "Xtrain_mean[!,:max_WC] = convert.(Float64,Xtrain_mean[!,:max_WC]);\n",
    "Xtrain_mean[!,:sentiment] = convert.(Float64,Xtrain_mean[!,:sentiment]);\n",
    "Xtrain_mean[!,:WC] = convert.(Float64,Xtrain_mean[!,:WC]);\n",
    "\n",
    "Xtest_mean[!,:faculty_app_scr] = convert.(Float64,Xtest_mean[!,:faculty_app_scr]);\n",
    "Xtest_mean[!,:min_WC] = convert.(Float64,Xtest_mean[!,:min_WC]);\n",
    "Xtest_mean[!,:max_WC] = convert.(Float64,Xtest_mean[!,:max_WC]);\n",
    "Xtest_mean[!,:sentiment] = convert.(Float64,Xtest_mean[!,:sentiment]);\n",
    "Xtest_mean[!,:WC] = convert.(Float64,Xtest_mean[!,:WC]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7b3ff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowmissing!(Xtrain_mean)\n",
    "for i in 1:nrow(Xtrain_mean)\n",
    "    for j in 1:ncol(Xtrain_mean)\n",
    "        if Xtrain_mean[i,j] == 0.0\n",
    "            Xtrain_mean[i,j] = missing\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f32b826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowmissing!(Xtest_mean)\n",
    "for i in 1:nrow(Xtest_mean)\n",
    "    for j in 1:ncol(Xtest_mean)\n",
    "        if Xtest_mean[i,j] == 0.0\n",
    "            Xtest_mean[i,j] = missing\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c7363a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in 1:ncol(Xtrain_mean)\n",
    "  idx_missing = ismissing.(Xtrain_mean[:,p])\n",
    "  Xtrain_mean[idx_missing,p] .= mean(Xtrain_mean[.!idx_missing,p]) \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8261011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in 1:ncol(Xtest_mean)\n",
    "  idx_missing = ismissing.(Xtest_mean[:,p])\n",
    "  Xtest_mean[idx_missing,p] .= mean(Xtest_mean[.!idx_missing,p]) \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96414371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature names - for interpretability purposes\n",
    "features = names(Xtrain_mean)\n",
    "p = length(features)\n",
    "feature_names = []\n",
    "for i=1:p\n",
    "    append!(feature_names,[features[i]])\n",
    "    append!(feature_names,[features[i]*\"_squared\"])\n",
    "    append!(feature_names,[features[i]*\"_sqrt\"])\n",
    "    append!(feature_names,[features[i]*\"_log\"])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0eee4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_mean = Matrix(Xtrain_mean);\n",
    "Xtest_mean = Matrix(Xtest_mean);\n",
    "Xtrain_mean = (Xtrain_mean .- mean(Xtrain_mean,dims=1))./std(Xtrain_mean,dims=1);\n",
    "Xtest_mean = (Xtest_mean .- mean(Xtest_mean,dims=1))./std(Xtest_mean,dims=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80bd6785",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: holistic_cv not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: holistic_cv not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[26]:10",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "# Regularization\n",
    "Γ_vals = [.001,.005,.01,.03,.1,.2,.3,.5,1.0]\n",
    "\n",
    "# Sparsity\n",
    "k_vals = [5]\n",
    "\n",
    "# Correlation\n",
    "ρ_max_vals = [0.7]\n",
    "\n",
    "β,β0,lambda = holistic_cv(Xtrain_mean,ytrain_mean,Γ_vals,k_vals,ρ_max_vals);\n",
    "indices_holistic = [i for i=1:length(β) if abs(β[i]) > .00001];\n",
    "println(\"\\nOptimal lambda: $lambda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e731e894",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: indices_holistic not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: indices_holistic not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ ./In[27]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "for i in indices_holistic\n",
    "    println(\"Selected $(feature_names[i]) with value $(β[i])\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7725acc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: β not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: β not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[28]:4",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "Xtrain_mean_ex = compute_nonlinear_transformations(Xtrain_mean)\n",
    "Xtest_mean_ex = compute_nonlinear_transformations(Xtest_mean)\n",
    "\n",
    "println(\"Train r2 = $(compute_r2(Xtrain_mean_ex,ytrain_mean,β,β0))\")\n",
    "println(\"Test r2 = $(compute_r2(Xtest_mean_ex,ytest_mean,β,β0))\")\n",
    "println()\n",
    "println(\"Train MSE = $(compute_mse(Xtrain_mean_ex,ytrain_mean,β,β0))\")\n",
    "println(\"Test MSE = $(compute_mse(Xtest_mean_ex,ytest_mean,β,β0))\")\n",
    "println()\n",
    "println(\"Sparsity: $(length(indices_holistic))\")\n",
    "println()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dae7b50",
   "metadata": {},
   "source": [
    "# Optimal Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce59598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_opt = (ytrain .- mean(ytrain))./std(ytrain);\n",
    "ytest_opt = (ytest .- mean(ytest))./std(ytest);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "782c80a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_opt = deepcopy(Xtrain);\n",
    "Xtest_opt = deepcopy(Xtest);\n",
    "\n",
    "vars = names(df)[[12,20,21,22,23,24,25,28,29,30,31,32,33,34,35,36,37,38,39,40,\n",
    "        41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,\n",
    "        66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81]];\n",
    "\n",
    "Xtrain_opt = Xtrain_opt[:,vars];\n",
    "Xtest_opt = Xtest_opt[:,vars];\n",
    "\n",
    "Xtrain_opt = coalesce.(Xtrain_opt,0);\n",
    "Xtest_opt = coalesce.(Xtest_opt,0);\n",
    "\n",
    "Xtrain_opt[!,:faculty_app_scr] = convert.(Float64,Xtrain_opt[!,:faculty_app_scr]);\n",
    "Xtrain_opt[!,:min_WC] = convert.(Float64,Xtrain_opt[!,:min_WC]);\n",
    "Xtrain_opt[!,:max_WC] = convert.(Float64,Xtrain_opt[!,:max_WC]);\n",
    "Xtrain_opt[!,:sentiment] = convert.(Float64,Xtrain_opt[!,:sentiment]);\n",
    "Xtrain_opt[!,:WC] = convert.(Float64,Xtrain_opt[!,:WC]);\n",
    "\n",
    "Xtest_opt[!,:faculty_app_scr] = convert.(Float64,Xtest_opt[!,:faculty_app_scr]);\n",
    "Xtest_opt[!,:min_WC] = convert.(Float64,Xtest_opt[!,:min_WC]);\n",
    "Xtest_opt[!,:max_WC] = convert.(Float64,Xtest_opt[!,:max_WC]);\n",
    "Xtest_opt[!,:sentiment] = convert.(Float64,Xtest_opt[!,:sentiment]);\n",
    "Xtest_opt[!,:WC] = convert.(Float64,Xtest_opt[!,:WC]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78805097",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowmissing!(Xtrain_opt)\n",
    "for i in 1:nrow(Xtrain_opt)\n",
    "    for j in 1:ncol(Xtrain_opt)\n",
    "        if Xtrain_opt[i,j] == 0.0\n",
    "            Xtrain_opt[i,j] = missing\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e80f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowmissing!(Xtest_opt)\n",
    "for i in 1:nrow(Xtest_opt)\n",
    "    for j in 1:ncol(Xtest_opt)\n",
    "        if Xtest_opt[i,j] == 0.0\n",
    "            Xtest_opt[i,j] = missing\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd1886f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: ProgressMeter by default refresh meters with additional information in IJulia via `IJulia.clear_output`, which clears all outputs in the cell. \n",
      "│  - To prevent this behaviour, do `ProgressMeter.ijulia_behavior(:append)`. \n",
      "│  - To disable this warning message, do `ProgressMeter.ijulia_behavior(:clear)`.\n",
      "└ @ ProgressMeter /Users/iai/builds/InterpretableAI/SystemImage/SysImgBuilder/.julia/packages/ProgressMeter/Vf8un/src/ProgressMeter.jl:620\n",
      "\u001b[32mTrying different warm starts...    100%|████████████████| Time: 0:00:31\u001b[39m\n",
      "\u001b[A4m  Warmstart:  rand\u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Xtrain_opt = IAI.impute(Xtrain_opt);\n",
    "Xtest_opt = IAI.impute(Xtest_opt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1fe992b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature names - for interpretability purposes\n",
    "features = names(Xtrain_opt)\n",
    "p = length(features)\n",
    "feature_names = []\n",
    "for i=1:p\n",
    "    append!(feature_names,[features[i]])\n",
    "    append!(feature_names,[features[i]*\"_squared\"])\n",
    "    append!(feature_names,[features[i]*\"_sqrt\"])\n",
    "    append!(feature_names,[features[i]*\"_log\"])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ada51ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_opt = Matrix(Xtrain_opt);\n",
    "Xtest_opt = Matrix(Xtest_opt);\n",
    "Xtrain_opt = (Xtrain_opt .- mean(Xtrain_opt,dims=1))./std(Xtrain_opt,dims=1);\n",
    "Xtest_opt = (Xtest_opt .- mean(Xtest_opt,dims=1))./std(Xtest_opt,dims=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a141cee9",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: holistic_cv not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: holistic_cv not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[36]:10",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "# Regularization\n",
    "Γ_vals = [.001,.005,.01,.03,.1,.2,.3,.5,1.0]\n",
    "\n",
    "# Sparsity\n",
    "k_vals = [5]\n",
    "\n",
    "# Correlation\n",
    "ρ_max_vals = [0.7]\n",
    "\n",
    "β,β0,lambda = holistic_cv(Xtrain_opt,ytrain_opt,Γ_vals,k_vals,ρ_max_vals);\n",
    "indices_holistic = [i for i=1:length(β) if abs(β[i]) > .00001];\n",
    "println(\"\\nOptimal lambda: $lambda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc77f29d",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: indices_holistic not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: indices_holistic not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ ./In[37]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "for i in indices_holistic\n",
    "    println(\"Selected $(feature_names[i]) with value $(β[i])\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "34af42ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: β not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: β not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[38]:4",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "Xtrain_opt_ex = compute_nonlinear_transformations(Xtrain_opt)\n",
    "Xtest_opt_ex = compute_nonlinear_transformations(Xtest_opt)\n",
    "\n",
    "println(\"Train r2 = $(compute_r2(Xtrain_opt_ex,ytrain_opt,β,β0))\")\n",
    "println(\"Test r2 = $(compute_r2(Xtest_opt_ex,ytest_opt,β,β0))\")\n",
    "println()\n",
    "println(\"Train MSE = $(compute_mse(Xtrain_opt_ex,ytrain_opt,β,β0))\")\n",
    "println(\"Test MSE = $(compute_mse(Xtest_opt_ex,ytest_opt,β,β0))\")\n",
    "println()\n",
    "println(\"Sparsity: $(length(indices_holistic))\")\n",
    "println()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0fb75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08db026a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lnr = IAI.ImputationLearner(method=:=opt_knn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
